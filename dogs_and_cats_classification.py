# -*- coding: utf-8 -*-
"""Dogs and Cats

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/ferroudjabtlb/dogs-and-cats.b344aea5-433a-4d75-8fad-b66d3f57ceef.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251205/auto/storage/goog4_request%26X-Goog-Date%3D20251205T115555Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4a952d1f2253b98504c2e472ae8a6657a26eb918b6140c2bf7b08b53ac185168db26131d593e94d1c7b7939d71fa2a15bce927d95b9980d86c6c22d0b8044965a46feff16302a5729207eacd5cee9d35503d7b2929275ca31ee5bef4fd88265db4c6e64467299db13565b795634f362729430cafbc52d891320775e29364133ee394ef1877c4e0d515e596d413c473cd0a7afca1313eec42d63651b439f7167d48f1ebb2ba999b4f1989c104da6d0833fbee72b3a2c3ec4065574f29a3de6e7296d4c60aba7beed2919f7b3f2cfd9ec3aed7b5700b3b6a8edec8b5a2cea735d0b47814a04385c7ca2c0ed9a57bfae744c4353733382e80b3e197668d5618d9df
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
moazeldsokyx_dogs_vs_cats_path = kagglehub.dataset_download('moazeldsokyx/dogs-vs-cats')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load
# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import kagglehub
import os, warnings
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#Import librairy
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import gridspec
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image_dataset_from_directory

"""# Setup"""

# Reproducability
def set_seed(seed=31415):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
set_seed()


# Set Matplotlib defaults
plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')
warnings.filterwarnings("ignore") # to clean up output cells

"""# Load data"""

data_train = image_dataset_from_directory('/kaggle/input/dogs-vs-cats/dataset/train',
                                        labels='inferred',
                                        label_mode='binary',
                                        image_size=[128, 128],
                                        interpolation='nearest',
                                        batch_size=64,
                                        shuffle=True,)

data_valid = image_dataset_from_directory('/kaggle/input/dogs-vs-cats/dataset/validation',
                                        labels='inferred',
                                        label_mode='binary',
                                        image_size=[128, 128],
                                        interpolation='nearest',
                                        batch_size=64,
                                        shuffle=True,)

data_test = image_dataset_from_directory('/kaggle/input/dogs-vs-cats/dataset/test',
                                        labels='inferred',
                                        label_mode='binary',
                                        image_size=[128, 128],
                                        interpolation='nearest',
                                        batch_size=64,
                                        shuffle=True,)

import plotly.express as px

class_names = ['Cats', 'Dogs']

n_dogs = len(os.listdir('/kaggle/input/dogs-vs-cats/dataset/train/dogs'))
n_cats = len(os.listdir('/kaggle/input/dogs-vs-cats/dataset/train/cats'))
n_images = [n_cats, n_dogs]
px.pie(names=class_names, values=n_images)

"""**As we can see the data is perfectly balanced**"""

# Data Pipeline
def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
ds_train = (
    data_train
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
ds_valid = (
    data_valid
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)

# display one batch from the dataset
def plot_data(dataset, n_images) :
    images, labels = next(iter(dataset))

    # display 7 pictures
    plt.figure(figsize=(12, 6))
    for i in range(n_images):
        plt.subplot(2, (n_images+1)//2, i+1)
        plt.imshow(images[i].numpy())
        plt.title("Dog" if labels[i].numpy() == 1 else "Cat")
        plt.axis("off")

    plt.show()

plot_data(ds_train, 7)
print("\n")
plot_data(ds_valid, 7)
print("\n")
plot_data(data_test, 7)

print("Data is ready to set the model and train")

"""# Model"""

# Define Base and Head

from tensorflow.keras import layers

model = keras.Sequential([

                         #block 1
                         layers.Conv2D(filters = 32, kernel_size = 5, activation = 'relu',
                                         input_shape=[128, 128, 3]),
                         layers.MaxPool2D(),

                         #block 2
                         layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'),
                         layers.MaxPool2D(),

                         #block 3
                         layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu'),
                         layers.MaxPool2D(),

                         #classifier Head
                         layers.Flatten(),
                         layers.Dense(6, 'relu'),
                         layers.Dense(2, 'softmax')
                        ])

model.summary()

#Training model

model.compile(
    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),
    loss = "sparse_categorical_crossentropy",
    metrics = ["accuracy"]
)

history = model.fit(
    ds_train,
    validation_data = ds_valid,
    epochs = 10,
    verbose = 0
)

"""# Evaluation"""

#Plot loss and metrics for training and validation datasets
history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot(title="Loss")
history_frame.loc[:, ['accuracy', 'val_accuracy']].plot(title="Accuracy")
plt.show()


print(("Best Validation Loss: {:0.4f}" +\
      "\nBest Validation Accuracy: {:0.4f}\n")\
      .format(history_frame['val_loss'].min(),
              history_frame['val_accuracy'].max()))

print(("Best training Loss: {:0.4f}" +\
      "\nBest training Accuracy: {:0.4f}")\
      .format(history_frame['loss'].min(),
              history_frame['accuracy'].max()))

# evaluate the model on the dataset "test"
test_loss, test_acc = model.evaluate(data_test)

print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_acc:.4f}")

"""# Visualize the predictions"""

def plot_prediction(dataset, model, class_names, n_images):
    i = 1
    # Get a batch
    images, labels = next(iter(dataset))

    # Gets the model predictions
    preds = model.predict(images)

    #output = softmax --> has 2 classes
    predictions = np.argmax(preds, axis=1)
    labels = labels.numpy().astype('int32')

    plt.figure(figsize=(14, 15))
    for img, label, pred in zip(images, labels, predictions):
        plt.subplot(4, 3, i)
        plt.imshow(img.numpy())
        title_obj = plt.title(class_names[pred])
        # vert si correct, rouge sinon
        plt.setp(title_obj, color='g' if pred == label else 'r')
        plt.axis('off')
        i += 1
        if i > n_images:
            break
    plt.show()

plot_prediction(data_test, model, class_names, 10)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Pr√©dictions sur tout le dataset test
y_true = []
y_pred = []

for images, labels in data_test:
    preds = model.predict(images, verbose = 0)
    preds = np.argmax(preds, axis=1)
    y_pred.extend(preds)
    y_true.extend(labels.numpy())

y_true = np.array(y_true)
y_pred = np.array(y_pred)

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(cm, display_labels=['Cat','Dog'])
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""**Prediction results :**

- True Cats correctly predicted as Cats: 4213
- True Cats incorrectly predicted as Dogs: 2029
- True Dogs correctly predicted as Dogs: 5526
- True Dogs incorrectly predicted as Cats: 693
"""

from sklearn.metrics import classification_report

print(classification_report(y_true, y_pred, target_names=['Cat','Dog']))